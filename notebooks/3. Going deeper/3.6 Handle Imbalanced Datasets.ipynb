{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parrot Prediction Courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Imbalanced Dataset\n",
    "\n",
    "> Imbalanced data refers to a classification problems where the classes are not equally distributed.\n",
    "\n",
    "It's very common problem, for example predicting frauds, where the number of postivie (frauds) instances is very small comparing to negative ones.\n",
    "\n",
    "You can read good introduction about tackling imbalanced datasets [here](http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/).\n",
    "\n",
    "\n",
    "LINKS:\n",
    "- https://github.com/dmlc/xgboost/blob/master/demo/kaggle-higgs/higgs-cv.py (setting ratio)\n",
    "- http://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation\n",
    "- https://github.com/dmlc/xgboost/issues/144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General advices\n",
    "These are some common tactics when approaching imbalanced datasets:\n",
    "\n",
    "- collect more data,\n",
    "- use better evaluation metric (that notices such mistakes - ie. AUC, F1, Kappa, ...),\n",
    "- try oversampling or undersampling,\n",
    "- generate artificial samples of minority class (ie. SMOTE algorithm),\n",
    "\n",
    "In XGBoost you can try to:\n",
    "- make sure that parameter `min_child_weight` is small (because leaf nodes can have smaller size groups), it is set to `min_child_weight=1` by default,\n",
    "- assign more weights to specific samples while initalizing `DMatrix`,\n",
    "- control the balance of positive and negative weights  using `set_pos_weight` parameter,\n",
    "- use AUC for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "Load essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# reproducibility\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate imbalanced dataset for binary classification. There will be only 10% (about 20 samples) of negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=200,\n",
    "    n_features=5,\n",
    "    n_informative=3,\n",
    "    n_classes=2,\n",
    "    weights=[.9, .1],\n",
    "    shuffle=True,\n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of negative instances: 21\n"
     ]
    }
   ],
   "source": [
    "print('Total number of negative instances: {}'.format(y.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of negative train instances: 14\n",
      "Total number of negative test instances: 7\n"
     ]
    }
   ],
   "source": [
    "print('Total number of negative train instances: {}'.format(y_train.sum()))\n",
    "print('Total number of negative test instances: {}'.format(y_test.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'max_depth':1,\n",
    "    'silent':1,\n",
    "    'eta':1\n",
    "}\n",
    "\n",
    "num_rounds = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "y_test_preds = (bst.predict(dtest) > 0.5).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0  1  All\n",
       "Actual               \n",
       "0          59  0   59\n",
       "1           4  3    7\n",
       "All        63  3   66"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    pd.Series(y_test, name='Actual'),\n",
    "    pd.Series(y_test_preds, name='Predicted'),\n",
    "    margins=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n",
      "Precision: 1.00\n",
      "Recall: 0.43\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {0:.2f}'.format(accuracy_score(y_test, y_test_preds)))\n",
    "print('Precision: {0:.2f}'.format(precision_score(y_test, y_test_preds)))\n",
    "print('Recall: {0:.2f}'.format(recall_score(y_test, y_test_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting an [accuracy paradox](https://en.wikipedia.org/wiki/Accuracy_paradox?oldformat=true)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focus on minority class\n",
    "Begin by calculating total number of positive and negative classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels = dtrain.get_label()\n",
    "\n",
    "ratio = float(np.sum(train_labels == 0)) / np.sum(train_labels == 1)\n",
    "params['scale_pos_weight'] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>51</td>\n",
       "      <td>15</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1  All\n",
       "Actual                \n",
       "0          51   8   59\n",
       "1           0   7    7\n",
       "All        51  15   66"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "y_test_preds = (bst.predict(dtest) > 0.5).astype('int')\n",
    "\n",
    "pd.crosstab(\n",
    "    pd.Series(y_test, name='Actual'),\n",
    "    pd.Series(y_test_preds, name='Predicted'),\n",
    "    margins=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n",
      "Precision: 0.47\n",
      "Recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {0:.2f}'.format(accuracy_score(y_test, y_test_preds)))\n",
    "print('Precision: {0:.2f}'.format(precision_score(y_test, y_test_preds)))\n",
    "print('Recall: {0:.2f}'.format(recall_score(y_test, y_test_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that we made a trade-off here. We are now able to perfectly classify the minority class, but got poor performance on majority.\n",
    "\n",
    "We can also set the weights manually while creating `DMatrix` objects. In this case we can help the algorithm to focus on particular instances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
