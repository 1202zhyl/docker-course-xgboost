{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parrot Prediction Courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias/variance trade-off\n",
    "\n",
    "The following notebook presents visual explanation about how to deal with bias/variance trade-off, which is common machine learning problem.\n",
    "\n",
    "**What you will learn**:\n",
    "\n",
    "- What is bias and variance in terms of ML problem\n",
    "- Detect and deal with under- and over-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias and variance\n",
    "There are two general types of errors made by classifiers - bias and variance errors.\n",
    "\n",
    "> **Bias error** is the overall difference between expected predictions made by the model and true values.\n",
    ">\n",
    "> **Variance error** describe how much predictions for the given point vary.\n",
    "\n",
    "The desired state is when both errors are as low as possible. The graphics taken from [Scott Fortmann-Roe's blog](http://scott.fortmann-roe.com/docs/BiasVariance.html) visualizes the issue really well. Imagine that the center of the target is the perfect model. We are iteratively repeating our experiment, recreating model and using it on the same data points.\n",
    "\n",
    "<img src='../images/bias-variance.png' width=\"500px\" height=\"500px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting and overfitting\n",
    "Knowing the errors introduced with bias and variance we can proceed to how these relate to training the model. We will use the plot taken from scikit-learn [docs](http://www.astroml.org/sklearn_tutorial/practical.html) to help us visualize the **underfitting** and **overfitting** issues.\n",
    "<img src='../images/underfitting_overfitting.png' />\n",
    "This simple example tries to fit a polynomial regression to predict future price. It's obious to see that for $d=1$ the model is too simple (underfits the data), and for $d=6$ is just the opposite (overfitting).\n",
    "\n",
    "> For **underfitting** we say that model suffers from *high bias* (too simple) (low variance)\n",
    ">\n",
    "> For **overfitting** we say that model suffers from *high variance* (over-complicated, unstable) (low bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to detect it\n",
    "To quantify the effects described we are going to train the model couple times for choosing different parameters value. Let's consider that we would like to find a optimal number of trees - we don't want the model to be very simple, but we also don't want to over-complicate it.\n",
    "\n",
    "The plan is as follows, we will:\n",
    "\n",
    "- generate complicated binary classification dataset,\n",
    "- use Scikit-learn wrapper,\n",
    "- train the model for different values of trees (`n_estimators)`) using stratified 10-fold CV,\n",
    "- plot train/test errors\n",
    "\n",
    "Begin with loading required libraries and setting random seed number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.learning_curve import validation_curve\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "# reproducibility\n",
    "seed = 123\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=8, n_redundant=3, n_repeated=2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will divide into 10 stratified folds (the same distibution of labels in each fold) for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the number of trees influence the predictions accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 1,\n",
    "    'learning_rate': 0.3,\n",
    "    'silent': 1.0\n",
    "}\n",
    "\n",
    "n_estimators_range = np.linspace(1, 200, 10).astype('int')\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(**default_params),\n",
    "    X, y,\n",
    "    param_name = 'n_estimators',\n",
    "    param_range = n_estimators_range,\n",
    "    cv=cv,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the validation curve plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=100)\n",
    "\n",
    "plt.title(\"Validation Curve with XGBoost (eta = 0.3)\")\n",
    "plt.xlabel(\"number of trees\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.7, 1.1)\n",
    "\n",
    "plt.plot(n_estimators_range,\n",
    "             train_scores_mean,\n",
    "             label=\"Training score\",\n",
    "             color=\"r\")\n",
    "\n",
    "plt.plot(n_estimators_range,\n",
    "             test_scores_mean, \n",
    "             label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "\n",
    "plt.fill_between(n_estimators_range, \n",
    "                 train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, \n",
    "                 alpha=0.2, color=\"r\")\n",
    "\n",
    "plt.fill_between(n_estimators_range,\n",
    "                 test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std,\n",
    "                 alpha=0.2, color=\"g\")\n",
    "\n",
    "plt.axhline(y=1, color='k', ls='dashed')\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "i = np.argmax(test_scores_mean)\n",
    "print(\"Best cross-validation result ({0:.2f}) obtained for {1} trees\".format(test_scores_mean[i], n_estimators_range[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot we can draw the following conclusions:\n",
    "\n",
    "- training score keeps growing while adding new trees, but from cerain point CV score is fixed\n",
    "- variance is lowest, and bias is high for less than 25 trees,\n",
    "- from about 25 trees, the variance is getting higher and while the CV score bias is holding steady (there is no point for adding extra trees / complexity)\n",
    "- we can see that the model is quite stable keeping variance fixed when increasing it's complexity\n",
    "\n",
    "We can assume that the trade-off for our model will be met at `n_estimators = 50`. The variance is still to big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we can do?\n",
    "\n",
    "#### Dealing with high variance\n",
    "If model is too complex try:\n",
    "- using less features (ie. feature selection),\n",
    "- using more training samples (ie. artificially generated),\n",
    "- increasing regularization (add penalties for extra complexity)\n",
    "\n",
    "In XGBoost you can try to:\n",
    "- reduce depth of each tree (`max_depth`),\n",
    "- increase `min_child_weight` parameter,\n",
    "- increase `gamma` parameter,\n",
    "- add more randomness using `subsample`, `colsample_bytree` parameters,\n",
    "- increase `lambda` and `alpha` regularization parameters\n",
    "\n",
    "#### Dealing with high bias\n",
    "If model is too simple:\n",
    "- add more features (ie. better feature engineering),\n",
    "- more sophisticated model\n",
    "- decrease regularization\n",
    "\n",
    "In XGBoost you can do it by:\n",
    "- increase depth of each tree (`max_depth`),\n",
    "- decrease `min_child_weight` parameter,\n",
    "- decrease `gamma` parameter,\n",
    "- decrease `lambda` and `alpha` regularization parameters\n",
    "\n",
    "Let's try to tweak a parameters a little bit. We are going to add some randomness - each tree we will use 70% randomly chosen samples and 60% randomly chosen features. This should help to reduce a variance. To decrease the bias (bigger accuracy) try adding an extra level to each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 2, # changed\n",
    "    'learning_rate': 0.3,\n",
    "    'silent': 1.0,\n",
    "    'colsample_bytree': 0.6, # added\n",
    "    'subsample': 0.7 # added\n",
    "}\n",
    "\n",
    "n_estimators_range = np.linspace(1, 200, 10).astype('int')\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(**default_params),\n",
    "    X, y,\n",
    "    param_name = 'n_estimators',\n",
    "    param_range = n_estimators_range,\n",
    "    cv=cv,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=100)\n",
    "\n",
    "plt.title(\"Validation Curve with XGBoost (eta = 0.3)\")\n",
    "plt.xlabel(\"number of trees\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.7, 1.1)\n",
    "\n",
    "plt.plot(n_estimators_range,\n",
    "             train_scores_mean,\n",
    "             label=\"Training score\",\n",
    "             color=\"r\")\n",
    "\n",
    "plt.plot(n_estimators_range,\n",
    "             test_scores_mean, \n",
    "             label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "\n",
    "plt.fill_between(n_estimators_range, \n",
    "                 train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, \n",
    "                 alpha=0.2, color=\"r\")\n",
    "\n",
    "plt.fill_between(n_estimators_range,\n",
    "                 test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std,\n",
    "                 alpha=0.2, color=\"g\")\n",
    "\n",
    "plt.axhline(y=1, color='k', ls='dashed')\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "i = np.argmax(test_scores_mean)\n",
    "print(\"Best cross-validation result ({0:.2f}) obtained for {1} trees\".format(test_scores_mean[i], n_estimators_range[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have obtained slightly less variance and decreased bias."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
