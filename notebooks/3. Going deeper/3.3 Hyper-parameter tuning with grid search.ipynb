{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parrot Prediction Courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning with grid search\n",
    "\n",
    "As you know there are plenty of tunable parameters. Each one results in different output. The question is which combination results in best output.\n",
    "\n",
    "The following notebook will show you how to configure Scikit-learn grid search module for figuring out the best parameters for your XGBoost model.\n",
    "\n",
    "**What you will learn:**\n",
    "- Finding best hyper-parameters for your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with loading all required libraries in one place and set seed number for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "# reproducibility\n",
    "seed = 123\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=8, n_redundant=3, n_repeated=2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define cross-validation strategy for testing. Let's use `StratifiedKFold` which guarantees that target label is equally distributed across each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a dictionary holding possible parameter values we want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'max_depth': [1, 2, 3],\n",
    "    'n_estimators': [5, 10, 25, 50],\n",
    "    'learning_rate': np.linspace(1e-16, 1, 3)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a dictiorany for fixed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `GridSearchCV` estimator. We will be looking for combination giving the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst_grid = GridSearchCV(\n",
    "    estimator=XGBClassifier(**params_fixed, seed=seed),\n",
    "    param_grid=params_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the calcuations notice that $3*4*3*10=360$ models will be created for testing all combinations. You should always have rough estimations about what is going to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.StratifiedKFold(labels=[1 0 ..., 0 1], n_folds=10, shuffle=True, random_state=123),\n",
       "       error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=123, silent=1, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': array([  1.00000e-16,   5.00000e-01,   1.00000e+00]), 'max_depth': [2, 3, 4], 'n_estimators': [5, 10, 25, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can look at all obtained scores, and try to manually see what matters and what not. A quick glance looks that the largeer `n_estimators` then the accuracy is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.50000, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 2, 'n_estimators': 5},\n",
       " mean: 0.50000, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 2, 'n_estimators': 10},\n",
       " mean: 0.50000, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 2, 'n_estimators': 25},\n",
       " mean: 0.50000, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 2, 'n_estimators': 50},\n",
       " mean: 0.50000, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 3, 'n_estimators': 5},\n",
       " mean: 0.50000, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 3, 'n_estimators': 10},\n",
       " mean: 0.50000, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 3, 'n_estimators': 25},\n",
       " mean: 0.50000, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 3, 'n_estimators': 50},\n",
       " mean: 0.50000, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 4, 'n_estimators': 5},\n",
       " mean: 0.50000, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 4, 'n_estimators': 10},\n",
       " mean: 0.50000, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 4, 'n_estimators': 25},\n",
       " mean: 0.50000, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 4, 'n_estimators': 50},\n",
       " mean: 0.88000, std: 0.02530, params: {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 5},\n",
       " mean: 0.90600, std: 0.01855, params: {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 10},\n",
       " mean: 0.91600, std: 0.02245, params: {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 25},\n",
       " mean: 0.92400, std: 0.02107, params: {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 50},\n",
       " mean: 0.90000, std: 0.02530, params: {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 5},\n",
       " mean: 0.91300, std: 0.02492, params: {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 10},\n",
       " mean: 0.92500, std: 0.01857, params: {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 25},\n",
       " mean: 0.93100, std: 0.01513, params: {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 50},\n",
       " mean: 0.90300, std: 0.02900, params: {'learning_rate': 0.5, 'max_depth': 4, 'n_estimators': 5},\n",
       " mean: 0.91500, std: 0.02655, params: {'learning_rate': 0.5, 'max_depth': 4, 'n_estimators': 10},\n",
       " mean: 0.92000, std: 0.02490, params: {'learning_rate': 0.5, 'max_depth': 4, 'n_estimators': 25},\n",
       " mean: 0.91900, std: 0.02343, params: {'learning_rate': 0.5, 'max_depth': 4, 'n_estimators': 50},\n",
       " mean: 0.87500, std: 0.02802, params: {'learning_rate': 1.0, 'max_depth': 2, 'n_estimators': 5},\n",
       " mean: 0.89000, std: 0.02236, params: {'learning_rate': 1.0, 'max_depth': 2, 'n_estimators': 10},\n",
       " mean: 0.90600, std: 0.03382, params: {'learning_rate': 1.0, 'max_depth': 2, 'n_estimators': 25},\n",
       " mean: 0.90600, std: 0.02245, params: {'learning_rate': 1.0, 'max_depth': 2, 'n_estimators': 50},\n",
       " mean: 0.89800, std: 0.02821, params: {'learning_rate': 1.0, 'max_depth': 3, 'n_estimators': 5},\n",
       " mean: 0.90200, std: 0.03187, params: {'learning_rate': 1.0, 'max_depth': 3, 'n_estimators': 10},\n",
       " mean: 0.91800, std: 0.02358, params: {'learning_rate': 1.0, 'max_depth': 3, 'n_estimators': 25},\n",
       " mean: 0.92400, std: 0.02154, params: {'learning_rate': 1.0, 'max_depth': 3, 'n_estimators': 50},\n",
       " mean: 0.90400, std: 0.03105, params: {'learning_rate': 1.0, 'max_depth': 4, 'n_estimators': 5},\n",
       " mean: 0.90600, std: 0.03292, params: {'learning_rate': 1.0, 'max_depth': 4, 'n_estimators': 10},\n",
       " mean: 0.92000, std: 0.02490, params: {'learning_rate': 1.0, 'max_depth': 4, 'n_estimators': 25},\n",
       " mean: 0.92000, std: 0.02683, params: {'learning_rate': 1.0, 'max_depth': 4, 'n_estimators': 50}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_grid.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are many results, we can sort or filter them manually or get best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy obtained: 0.931\n",
      "Parameters:\n",
      "\tlearning_rate: 0.5\n",
      "\tmax_depth: 3\n",
      "\tn_estimators: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Best accuracy obtained: {0}\".format(bst_grid.best_score_))\n",
    "print(\"Parameters:\")\n",
    "for key, value in bst_grid.best_params_.items():\n",
    "    print(\"\\t{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for best parameters is an iterative process. You should start with coarsed-granularity and move to to more detailed values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
